                                                                                                                                                                                           
{'loss': 1.8274, 'grad_norm': 2.6058966445713745, 'learning_rate': 0.00019230769230769233, 'epoch': 0.04}
{'loss': 1.7603, 'grad_norm': 2.489670613011379, 'learning_rate': 0.00018461538461538463, 'epoch': 0.08}
{'loss': 1.7504, 'grad_norm': 0.925432904273402, 'learning_rate': 0.00017692307692307693, 'epoch': 0.12}
{'loss': 1.5969, 'grad_norm': 0.9210938894526803, 'learning_rate': 0.00016923076923076923, 'epoch': 0.15}
{'loss': 1.5949, 'grad_norm': 1.2284658531231216, 'learning_rate': 0.00016153846153846155, 'epoch': 0.19}
{'loss': 1.4948, 'grad_norm': 0.4729872163141779, 'learning_rate': 0.00015384615384615385, 'epoch': 0.23}
{'loss': 1.4912, 'grad_norm': 0.3377101164296261, 'learning_rate': 0.00014615384615384615, 'epoch': 0.27}
{'loss': 1.3662, 'grad_norm': 0.23641277959917584, 'learning_rate': 0.00013846153846153847, 'epoch': 0.31}
{'loss': 1.3076, 'grad_norm': 0.5675243073576649, 'learning_rate': 0.00013076923076923077, 'epoch': 0.35}
{'loss': 1.352, 'grad_norm': 0.2717224556771252, 'learning_rate': 0.0001230769230769231, 'epoch': 0.38}
Invalidate trace cache @ step 1126: expected module 1, but got module 2332
  partition = torch.load(path, map_location=map_location)                                                                                                                                  
{'eval_loss': 1.3230516910552979, 'eval_runtime': 1.8312, 'eval_samples_per_second': 54.063, 'eval_steps_per_second': 2.184, 'epoch': 0.38}
Invalidate trace cache @ step 1126: expected module 2332, but got module 1
{'loss': 1.307, 'grad_norm': 0.2019198968252305, 'learning_rate': 0.00011538461538461538, 'epoch': 0.42}
{'loss': 1.3169, 'grad_norm': 0.1907179570088927, 'learning_rate': 0.0001076923076923077, 'epoch': 0.46}
{'loss': 1.2764, 'grad_norm': 0.21319685914426384, 'learning_rate': 0.0001, 'epoch': 0.5}
{'loss': 1.2667, 'grad_norm': 0.22544309679405816, 'learning_rate': 9.230769230769232e-05, 'epoch': 0.54}
{'loss': 1.2955, 'grad_norm': 0.1543052958769981, 'learning_rate': 8.461538461538461e-05, 'epoch': 0.58}
{'loss': 1.2557, 'grad_norm': 0.1415883066210692, 'learning_rate': 7.692307692307693e-05, 'epoch': 0.62}
{'loss': 1.3209, 'grad_norm': 0.15161280596093188, 'learning_rate': 6.923076923076924e-05, 'epoch': 0.65}
{'loss': 1.2786, 'grad_norm': 0.1898025093998101, 'learning_rate': 6.153846153846155e-05, 'epoch': 0.69}
{'loss': 1.2865, 'grad_norm': 0.16358530537465918, 'learning_rate': 5.384615384615385e-05, 'epoch': 0.73}
{'loss': 1.2872, 'grad_norm': 0.12884220327622778, 'learning_rate': 4.615384615384616e-05, 'epoch': 0.77}
Invalidate trace cache @ step 1126: expected module 1, but got module 2332
{'eval_loss': 1.2697495222091675, 'eval_runtime': 1.8634, 'eval_samples_per_second': 53.129, 'eval_steps_per_second': 2.147, 'epoch': 0.77}
Invalidate trace cache @ step 1126: expected module 2332, but got module 1
{'loss': 1.2607, 'grad_norm': 0.13341877744245922, 'learning_rate': 3.846153846153846e-05, 'epoch': 0.81}
{'loss': 1.2184, 'grad_norm': 0.12647521167905873, 'learning_rate': 3.0769230769230774e-05, 'epoch': 0.85}
{'loss': 1.2737, 'grad_norm': 0.13164996478570004, 'learning_rate': 2.307692307692308e-05, 'epoch': 0.88}
{'loss': 1.3242, 'grad_norm': 0.21391576491648828, 'learning_rate': 1.5384615384615387e-05, 'epoch': 0.92}
{'loss': 1.2266, 'grad_norm': 0.12676632682524344, 'learning_rate': 7.692307692307694e-06, 'epoch': 0.96}
{'loss': 1.2883, 'grad_norm': 0.1534566532465939, 'learning_rate': 0.0, 'epoch': 1.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26/26 [01:00<00:00,  2.32s/it]
{'train_runtime': 61.6501, 'train_samples_per_second': 13.236, 'train_steps_per_second': 0.422, 'train_loss': 1.3855831439678485, 'epoch': 1.0}
***** train metrics *****
  epoch                    =        1.0
  total_flos               =    18538GF
  train_loss               =     1.3856
  train_runtime            = 0:01:01.65
  train_samples            =       2250
  train_samples_per_second =     13.236
  train_steps_per_second   =      0.422
2025-05-22 17:44:21,952 - __main__ - INFO - *** Save model ***
INFO:__main__:*** Save model ***
[34m[1mwandb[0m: [33mWARNING[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.
2025-05-22 17:44:31,454 - __main__ - INFO - Model saved to finetuning-codes/runs/qwen-2.5-7b-alpaca
INFO:__main__:Model saved to finetuning-codes/runs/qwen-2.5-7b-alpaca
2025-05-22 17:44:31,627 - __main__ - INFO - Tokenizer saved to finetuning-codes/runs/qwen-2.5-7b-alpaca
INFO:__main__:Tokenizer saved to finetuning-codes/runs/qwen-2.5-7b-alpaca
2025-05-22 17:44:31,638 - __main__ - INFO - Pushing to hub...
INFO:__main__:Pushing to hub...
No files have been modified since last commit. Skipping to prevent empty commit.
WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.
2025-05-22 17:44:36,699 - __main__ - INFO - *** Training complete! ***
INFO:__main__:*** Training complete! ***
